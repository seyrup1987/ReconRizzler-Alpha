# Filename: VulnerabilityChecks/SqlInjectionPostgreScanRule.py

import asyncio
import logging
import random
import re
import time
import urllib.parse
from dataclasses import dataclass, field # Kept for DetachedResponse if used locally
from typing import Any, Dict, List, Optional, Tuple, Callable, Set

import aiohttp
# Attempt to import numpy for linear regression, optional
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    # Fallback: simple slope/correlation check if numpy not available

# Import the corrected Alert class and Tech enum from the generic SQLi rule
from .SqlInjectionScanRule import SQLiAlert, Tech # CORRECTED IMPORT

# --- PostgreSQL Specific Constants and Payloads ---
POSTGRES_SQL_ONE_LINE_COMMENT = "-- " # Note the space after --

ORIG_VALUE_TOKEN = "<<<<ORIGINALVALUE>>>>"
SLEEP_TOKEN = "<<<<SLEEP>>>>"

SQL_POSTGRES_TIME_FUNCTION_TEMPLATE = f"case when cast(pg_sleep({SLEEP_TOKEN}) as varchar) > '' then 0 else 1 end"

SQL_POSTGRES_TIME_PAYLOAD_TEMPLATES = [
    SQL_POSTGRES_TIME_FUNCTION_TEMPLATE,
    SQL_POSTGRES_TIME_FUNCTION_TEMPLATE + POSTGRES_SQL_ONE_LINE_COMMENT,
    "'" + SQL_POSTGRES_TIME_FUNCTION_TEMPLATE + POSTGRES_SQL_ONE_LINE_COMMENT,
    "\"" + SQL_POSTGRES_TIME_FUNCTION_TEMPLATE + POSTGRES_SQL_ONE_LINE_COMMENT,
    f"{ORIG_VALUE_TOKEN} ; SELECT {SQL_POSTGRES_TIME_FUNCTION_TEMPLATE} {POSTGRES_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}' ; SELECT {SQL_POSTGRES_TIME_FUNCTION_TEMPLATE} {POSTGRES_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}\" ; SELECT {SQL_POSTGRES_TIME_FUNCTION_TEMPLATE} {POSTGRES_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN} AND (SELECT CASE WHEN pg_sleep({SLEEP_TOKEN}) IS NULL THEN 1 ELSE 1 END) = 1 {POSTGRES_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}' AND (SELECT CASE WHEN pg_sleep({SLEEP_TOKEN}) IS NULL THEN 1 ELSE 1 END) = 1 {POSTGRES_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}\" AND (SELECT CASE WHEN pg_sleep({SLEEP_TOKEN}) IS NULL THEN 1 ELSE 1 END) = 1 {POSTGRES_SQL_ONE_LINE_COMMENT}",
]

POSTGRES_ERROR_PATTERNS = [
    re.compile(r"org\.postgresql\.util\.PSQLException", re.IGNORECASE | re.DOTALL),
    re.compile(r"PostgreSQL\s+JDBC\s+Driver", re.IGNORECASE | re.DOTALL),
    re.compile(r"ERROR:\s*syntax error at or near", re.IGNORECASE | re.DOTALL),
    re.compile(r"unterminated quoted string", re.IGNORECASE | re.DOTALL),
    re.compile(r"invalid input syntax for type", re.IGNORECASE | re.DOTALL), # Common PG error
]


class SqlInjectionPostgreScanRule:
    tech_required: Set[str] = { # Ensure lowercase
        "spip", "supabase", "postgresql", "graphcms", "postgis" # Added postgis as it implies postgresql
    }

    def __init__(self,
                 parent_logger: Optional[logging.Logger] = None,
                 active_scan_async_q: Optional[asyncio.Queue] = None, # Added
                 http_timeout: float = 20.0, # Default, can be overridden by ActiveVulnerabilityCheck
                 # Rule-specific configurations
                 max_time_requests_per_template: int = 3,
                 default_sleep_seconds: int = 5,
                 blind_request_limit_for_timing: int = 4,
                 time_correlation_error_range: float = 0.15,
                 time_slope_error_range: float = 0.30,
                 **kwargs # To accept other potential args from sqli_generic_config
                 ):
        self.logger = parent_logger or logging.getLogger(__name__)
        self.active_scan_async_q = active_scan_async_q # Store it
        self.http_timeout = http_timeout
        
        self.max_time_requests_per_template = max_time_requests_per_template
        self.default_sleep_seconds = default_sleep_seconds
        self.blind_request_limit_for_timing = max(2, blind_request_limit_for_timing)
        self.time_correlation_error_range = time_correlation_error_range
        self.time_slope_error_range = time_slope_error_range
        
        self._time_requests_count_per_scan_call = 0 # Reset per scan() call
        self.logger.debug(f"SqlInjectionPostgreScanRule initialized. Timeout: {self.http_timeout}s, Sleep: {self.default_sleep_seconds}s")

    async def _emit_alert(self, alert_obj: SQLiAlert): # Using imported SQLiAlert
        if self.active_scan_async_q:
            try:
                await self.active_scan_async_q.put({
                    "type": "active_scan_alert", "alert": alert_obj.as_dict()
                })
                self.logger.info(f"SQLiPostgre: Emitted alert - {alert_obj.name} for {alert_obj.uri}")
            except Exception as e:
                self.logger.error(f"SQLiPostgre: Failed to emit alert to queue: {e}")
        else:
            self.logger.warning(f"SQLiPostgre: Async queue not available. Alert not emitted: {alert_obj.name}")

    async def _send_request_async(
        self, session: aiohttp.ClientSession, method: str, url: str,
        headers: Dict[str, str], cookies: Dict[str, str],
        data: Optional[Any] = None, param_name_attacked: Optional[str] = None,
        payload_used: Optional[str] = None
    ) -> Tuple[Optional[Any], Optional[str], float]: # DetachedResponse, text, duration_ms
        start_time = time.monotonic()
        response_text: Optional[str] = None
        aio_response_status: Optional[int] = None
        aio_response_headers: Optional[Dict[str,str]] = None
        
        current_headers = headers.copy()
        if "User-Agent" not in current_headers:
             current_headers["User-Agent"] = "PostgreSQLScanner/1.0"

        log_payload_snippet = str(payload_used)[:50] + "..." if payload_used and len(payload_used) > 50 else payload_used
        self.logger.debug(f"Postgres Sending {method} to {url} (Param: {param_name_attacked}, Payload: {log_payload_snippet})")

        try:
            current_timeout_seconds = self.http_timeout
            if payload_used and "pg_sleep" in payload_used:
                sleep_match = re.search(r"pg_sleep\((\d+)\)", payload_used)
                if sleep_match:
                    try:
                        injected_sleep = int(sleep_match.group(1))
                        # Add buffer to default http_timeout, or ensure it's at least injected_sleep + buffer
                        current_timeout_seconds = max(self.http_timeout, injected_sleep + self.default_sleep_seconds + 5.0)
                    except ValueError: pass
            
            timeout = aiohttp.ClientTimeout(total=current_timeout_seconds)
            request_data_for_aiohttp = data
            if isinstance(data, dict) and method.upper() == "POST" and \
               (not current_headers.get("Content-Type") or "application/x-www-form-urlencoded" in current_headers.get("Content-Type","").lower()):
                form = aiohttp.FormData()
                for k, v_item in data.items(): form.add_field(k, str(v_item))
                request_data_for_aiohttp = form

            async with session.request(
                method.upper(), url, headers=current_headers, cookies=cookies, 
                data=request_data_for_aiohttp, timeout=timeout, allow_redirects=False
            ) as resp:
                aio_response_status = resp.status
                aio_response_headers = dict(resp.headers)
                response_text = await resp.text(errors='replace')
            
            duration_ms = (time.monotonic() - start_time) * 1000
            self.logger.debug(f"Postgres Response from {url}: Status {aio_response_status}, Duration: {duration_ms:.0f}ms")

            @dataclass
            class DetachedResponse: status: int; headers: Dict[str, str]; text_content: Optional[str]
            return DetachedResponse(status=aio_response_status, headers=aio_response_headers, text_content=response_text), response_text, duration_ms
        except asyncio.TimeoutError:
            self.logger.warning(f"Postgres Timeout ({current_timeout_seconds}s) for {method} {url} (Payload: {log_payload_snippet})")
            return None, None, current_timeout_seconds * 1000
        except aiohttp.ClientError as e:
            self.logger.warning(f"Postgres AIOHTTP ClientError for {method} {url} (Payload: {log_payload_snippet}): {type(e).__name__} - {e}")
            return None, None, (time.monotonic() - start_time) * 1000
        except Exception as e:
            self.logger.error(f"Postgres Unexpected error for {method} {url} (Payload: {log_payload_snippet}): {e}", exc_info=True)
            return None, None, (time.monotonic() - start_time) * 1000

    def _build_request_params(self, base_url: str, injection_location: str, param_name: str, payload: str, original_value: str, method: str, original_form_data: Optional[Dict[str, str]] = None) -> Tuple[str, Optional[Dict[str, str]]]:
        target_url = base_url; request_data: Optional[Dict[str, str]] = None
        if injection_location == "url_params":
            parsed_url = urllib.parse.urlparse(base_url)
            query_params = urllib.parse.parse_qs(parsed_url.query, keep_blank_values=True)
            query_params[param_name] = [payload]
            target_url = parsed_url._replace(query=urllib.parse.urlencode(query_params, doseq=True)).geturl()
        elif injection_location in ["form_data_post", "form_data_get"] :
            request_data = (original_form_data or {}).copy()
            request_data[param_name] = payload
            target_url = base_url
            if injection_location == "form_data_get" and method.upper() == "GET":
                parsed_url = urllib.parse.urlparse(base_url)
                query_params = urllib.parse.parse_qs(parsed_url.query, keep_blank_values=True)
                for k, v_item in request_data.items(): query_params[k] = [str(v_item)]
                target_url = parsed_url._replace(query=urllib.parse.urlencode(query_params, doseq=True)).geturl()
                request_data = None
        return target_url, request_data

    async def _check_timing_dependence_async(
        self, session: aiohttp.ClientSession, base_url: str,
        original_headers: Dict[str, str], original_cookies: Dict[str, str],
        injection_details: Dict[str, Any], payload_template: str
    ) -> Tuple[bool, Optional[str], Optional[float], Optional[str]]:
        param_name = injection_details["param_name"]; original_value = injection_details["original_value"]; location = injection_details["location"]; method = injection_details.get("method", "GET"); all_form_fields = injection_details.get("all_form_fields")
        current_test_sleep_s = self.default_sleep_seconds
        sleep_values_s = [0]
        if self.blind_request_limit_for_timing > 1: sleep_values_s.append(current_test_sleep_s / 2)
        if self.blind_request_limit_for_timing > 2: sleep_values_s.append(current_test_sleep_s)
        if self.blind_request_limit_for_timing > 3: sleep_values_s.append(current_test_sleep_s * 1.5)
        if self.blind_request_limit_for_timing > 4: sleep_values_s.append(current_test_sleep_s * 2)
        sleep_values_s = sorted(list(set(s for s in sleep_values_s if s >=0)))[:self.blind_request_limit_for_timing]
        if len(sleep_values_s) < 2 : return False, None, None, None

        observed_times_ms: List[float] = []; actual_sleeps_s: List[float] = []
        final_attack_payload_for_alert: Optional[str] = None; max_observed_time_ms: float = 0.0

        for sleep_s in sleep_values_s:
            if self._time_requests_count_per_scan_call >= self.max_time_requests_per_template: break # Cap per template
            payload_with_orig = payload_template.replace(ORIG_VALUE_TOKEN, original_value)
            attack_payload = payload_with_orig.replace(SLEEP_TOKEN, str(int(sleep_s)))
            current_headers = original_headers.copy(); current_cookies = original_cookies.copy()
            if location == "header": current_headers[param_name] = attack_payload
            elif location == "cookie": current_cookies[param_name] = attack_payload
            target_url, request_data = self._build_request_params(base_url, location, param_name, attack_payload, original_value, method, all_form_fields)
            if location in ["header", "cookie"]: target_url, request_data = base_url, None
            
            self._time_requests_count_per_scan_call += 1
            resp_obj, resp_text, duration_ms = await self._send_request_async(session, method, target_url, current_headers, current_cookies, request_data, param_name, attack_payload)
            if resp_obj is None: continue
            if resp_text:
                for err_pattern in POSTGRES_ERROR_PATTERNS:
                    match = err_pattern.search(resp_text)
                    if match:
                        self.logger.info(f"Postgres Error (from Time Test): Pattern '{err_pattern.pattern}' matched for '{param_name}'")
                        return True, attack_payload, duration_ms, f"PostgreSQL error pattern matched: {err_pattern.pattern}. Evidence: {match.group(0)[:100]}"
            actual_sleeps_s.append(sleep_s); observed_times_ms.append(duration_ms)
            if duration_ms > max_observed_time_ms: max_observed_time_ms = duration_ms; final_attack_payload_for_alert = attack_payload
        
        if len(actual_sleeps_s) < 2: return False, None, None, None
        if NUMPY_AVAILABLE:
            try:
                x = np.array(actual_sleeps_s); y = np.array(observed_times_ms) / 1000.0
                coeffs = np.polyfit(x, y, 1); slope = coeffs[0]
                correlation_matrix = np.corrcoef(x, y); correlation_xy = correlation_matrix[0,1]; r_squared = correlation_xy**2
                self.logger.debug(f"Postgres Timing (Numpy): Sleeps(s)={x}, Times(s)={y}, Slope={slope:.2f}, R^2={r_squared:.2f}")
                slope_ok = abs(slope - 1.0) < self.time_slope_error_range
                correlation_ok = r_squared > (1.0 - self.time_correlation_error_range)
                if slope_ok and correlation_ok:
                    evidence = f"Timing (Numpy): Sleeps(s): {actual_sleeps_s}, Times(ms): {[round(t) for t in observed_times_ms]}. Slope: {slope:.2f}, R^2: {r_squared:.2f}."
                    return True, final_attack_payload_for_alert, max_observed_time_ms, evidence
            except Exception as e_numpy: self.logger.warning(f"Postgres Timing: Numpy analysis failed: {e_numpy}.")
        
        if 0.0 in actual_sleeps_s: # Fallback simple check
            idx_zero_sleep = actual_sleeps_s.index(0.0); time_at_zero_sleep_ms = observed_times_ms[idx_zero_sleep]
            for i, s_val in enumerate(actual_sleeps_s):
                if s_val > 0:
                    t_val_ms = observed_times_ms[i]; diff_ms = t_val_ms - time_at_zero_sleep_ms
                    expected_diff_ms = s_val * 1000
                    lower_bound = expected_diff_ms * (1.0 - self.time_slope_error_range) - 500
                    upper_bound = expected_diff_ms * (1.0 + self.time_slope_error_range) + 500
                    if lower_bound <= diff_ms <= upper_bound and diff_ms > self.default_sleep_seconds * 1000 * 0.5 :
                        evidence = f"Timing (Simple): Sleeps(s): {actual_sleeps_s}, Times(ms): {[round(t) for t in observed_times_ms]}. For sleep={s_val}s, observed_delay={diff_ms:.0f}ms."
                        return True, final_attack_payload_for_alert, max_observed_time_ms, evidence
        return False, None, None, None

    async def scan(
        self,
        original_url: str,
        aiohttp_session: aiohttp.ClientSession,
        injection_details: Dict[str, Any],
        original_headers: Dict[str, str],
        original_cookies: Dict[str, str],
        # Other common args
        base_app_url: Optional[str] = None,
        html_content: Optional[str] = None,
        worker_ident: Optional[str] = "SQLiPostgreScan",
        page_specific_technologies: Optional[List[str]] = None,
        service_type_hint: Optional[str] = None,
        attack_strength: str = "MEDIUM" # Not directly used by this rule's current logic, but good for signature
    ) -> None: # Changed return type
        self._time_requests_count_per_scan_call = 0
        
        param_name = injection_details.get("param_name")
        location = injection_details.get("location")
        target_url_for_tests = injection_details.get("action_url", original_url)

        if not param_name:
            self.logger.debug(f"[{worker_ident}] PostgreSQL SQLi: No param_name. Skipping.")
            return

        self.logger.info(f"[{worker_ident}] Starting PostgreSQL Time-Based SQLi for param: '{param_name}' at '{location}' on URL: {target_url_for_tests}")

        for payload_template in SQL_POSTGRES_TIME_PAYLOAD_TEMPLATES:
            if self._time_requests_count_per_scan_call >= self.max_time_requests_per_template * len(SQL_POSTGRES_TIME_PAYLOAD_TEMPLATES):
                self.logger.debug(f"[{worker_ident}] PostgreSQL Scan: Reached max time-based request limit for param '{param_name}'.")
                break
            
            is_vulnerable, attack_payload, _, evidence_details_str = await self._check_timing_dependence_async(
                aiohttp_session, target_url_for_tests, original_headers, original_cookies,
                injection_details, payload_template
            )

            if is_vulnerable and attack_payload and evidence_details_str:
                alert_name = "SQL Injection - PostgreSQL Time Based"
                alert_desc = "A time-based SQL injection vulnerability specific to PostgreSQL was detected."
                injection_type_str = "Time-based (PostgreSQL pg_sleep)"
                confidence = 2

                if "error pattern matched" in evidence_details_str.lower():
                    alert_name = "SQL Injection - PostgreSQL Error Based (from Time Test)"
                    alert_desc = f"A PostgreSQL error was detected during a time-based test: {evidence_details_str}"
                    injection_type_str = "Error-based (PostgreSQL specific)"
                    confidence = 3

                alert = SQLiAlert(
                    cwe_id=89, name=alert_name, description=alert_desc,
                    uri=target_url_for_tests, param=param_name, attack=attack_payload,
                    evidence=evidence_details_str, rdbms=str(Tech.PostgreSQL),
                    injection_type=injection_type_str, confidence=confidence
                )
                alert.attack_details = {"location": location, "param": param_name, "method": injection_details.get("method", "GET")}
                await self._emit_alert(alert)
                self.logger.info(f"[{worker_ident}] PostgreSQL SQLi found for param '{param_name}'. Stopping further tests for this param with this rule.")
                break 
            
        self.logger.info(f"[{worker_ident}] PostgreSQL SQLi scan for param: '{param_name}' completed.")