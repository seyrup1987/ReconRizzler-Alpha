# Filename: VulnerabilityChecks/SqlInjectionMySqlScanRule.py

import asyncio
import logging
import random
import re
import time
import urllib.parse
from dataclasses import dataclass, field # Kept for DetachedResponse
from typing import Any, Dict, List, Optional, Tuple, Callable, Set

import aiohttp
# Attempt to import numpy for linear regression, optional
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# Import the corrected Alert class and Tech enum from the generic SQLi rule
from .SqlInjectionScanRule import SQLiAlert, Tech # CORRECTED IMPORT

# --- MySQL Specific Constants and Payloads ---
MYSQL_SQL_ONE_LINE_COMMENT = " -- -" # MySQL often needs a space after --, or use #
ORIG_VALUE_TOKEN = "<<<<ORIGINALVALUE>>>>"
SLEEP_TOKEN = "<<<<SLEEP>>>>"

SQL_MYSQL_TIME_PAYLOAD_TEMPLATES = [
    f"{ORIG_VALUE_TOKEN} AND SLEEP({SLEEP_TOKEN}){MYSQL_SQL_ONE_LINE_COMMENT}", # Common
    f"{ORIG_VALUE_TOKEN}' AND SLEEP({SLEEP_TOKEN}) AND '1'='1{MYSQL_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}\" AND SLEEP({SLEEP_TOKEN}) AND \"1\"=\"1{MYSQL_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN} OR SLEEP({SLEEP_TOKEN}){MYSQL_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}' OR SLEEP({SLEEP_TOKEN}) OR '1'='1{MYSQL_SQL_ONE_LINE_COMMENT}",
    f"{ORIG_VALUE_TOKEN}\" OR SLEEP({SLEEP_TOKEN}) OR \"1\"=\"1{MYSQL_SQL_ONE_LINE_COMMENT}",
    # Stacked query attempts (often disabled)
    f";SELECT SLEEP({SLEEP_TOKEN}){MYSQL_SQL_ONE_LINE_COMMENT}",
    f"';SELECT SLEEP({SLEEP_TOKEN}){MYSQL_SQL_ONE_LINE_COMMENT}",
    # Payloads from ZAP (some might be redundant or very specific)
    f"{ORIG_VALUE_TOKEN} / SLEEP({SLEEP_TOKEN}) ", # Division by sleep can cause error or delay
    f"{ORIG_VALUE_TOKEN}' / SLEEP({SLEEP_TOKEN}) / '",
    f"{ORIG_VALUE_TOKEN}\" / SLEEP({SLEEP_TOKEN}) / \"",
]
MYSQL_ERROR_PATTERNS = [
    re.compile(r"You have an error in your SQL syntax", re.IGNORECASE | re.DOTALL),
    re.compile(r"com\.mysql\.jdbc", re.IGNORECASE | re.DOTALL), # Older driver
    re.compile(r"com\.mysql\.cj\.jdbc", re.IGNORECASE | re.DOTALL), # Newer driver
    re.compile(r"Unknown column '[^']+' in 'where clause'",re.IGNORECASE | re.DOTALL),
    re.compile(r"COLLATION '.+' is not valid for CHARACTER SET", re.IGNORECASE | re.DOTALL),
    re.compile(r"Illegal mix of collations", re.IGNORECASE | re.DOTALL),
]

class SqlInjectionMySqlScanRule:
    tech_required: Set[str] = {"mysql", "mariadb"} # Primary triggers

    def __init__(self,
                 parent_logger: Optional[logging.Logger] = None,
                 active_scan_async_q: Optional[asyncio.Queue] = None, # Added
                 http_timeout: float = 20.0, # Default, can be overridden
                 # Rule-specific configurations
                 max_payload_templates_to_try: int = 4, # Reduced default
                 default_sleep_seconds: int = 5,
                 blind_request_limit_for_timing: int = 3, # Reduced default
                 time_correlation_error_range: float = 0.20, # Slightly more lenient
                 time_slope_error_range: float = 0.35,     # Slightly more lenient
                 **kwargs # To accept other potential args from sqli_generic_config
                 ):
        self.logger = parent_logger or logging.getLogger(__name__)
        self.active_scan_async_q = active_scan_async_q
        self.http_timeout = http_timeout
        
        self.max_payload_templates_to_try = min(max_payload_templates_to_try, len(SQL_MYSQL_TIME_PAYLOAD_TEMPLATES))
        self.default_sleep_seconds = default_sleep_seconds
        self.blind_request_limit_for_timing = max(2, blind_request_limit_for_timing)
        self.time_correlation_error_range = time_correlation_error_range
        self.time_slope_error_range = time_slope_error_range
        
        self._time_requests_count_total_for_param_scan = 0 # Reset per scan() call
        self.logger.debug(f"SqlInjectionMySqlScanRule initialized. Timeout: {self.http_timeout}s, Sleep: {self.default_sleep_seconds}s")

    async def _emit_alert(self, alert_obj: SQLiAlert):
        if self.active_scan_async_q:
            try:
                await self.active_scan_async_q.put({"type": "active_scan_alert", "alert": alert_obj.as_dict()})
                self.logger.info(f"SQLiMySQL: Emitted alert - {alert_obj.name} for {alert_obj.uri}")
            except Exception as e:
                self.logger.error(f"SQLiMySQL: Failed to emit alert to queue: {e}")
        else:
            self.logger.warning(f"SQLiMySQL: Async queue not available. Alert not emitted: {alert_obj.name}")

    async def _send_request_async(
        self, session: aiohttp.ClientSession, method: str, url: str,
        headers: Dict[str, str], cookies: Dict[str, str],
        data: Optional[Any] = None, param_name_attacked: Optional[str] = None,
        payload_used: Optional[str] = None
    ) -> Tuple[Optional[Any], Optional[str], float]: # DetachedResponse, text, duration_ms
        start_time = time.monotonic()
        response_text: Optional[str] = None
        aio_response_status: Optional[int] = None
        aio_response_headers: Optional[Dict[str,str]] = None
        
        current_headers = headers.copy()
        if "User-Agent" not in current_headers:
             current_headers["User-Agent"] = "MySQLScanner/1.0"

        log_payload_snippet = str(payload_used)[:50] + "..." if payload_used and len(payload_used) > 50 else payload_used
        self.logger.debug(f"MySQL Sending {method} to {url} (Param: {param_name_attacked}, Payload: {log_payload_snippet})")

        try:
            current_timeout_seconds = self.http_timeout
            if payload_used and "SLEEP(" in payload_used.upper(): # Case insensitive check for SLEEP
                sleep_match = re.search(r"SLEEP\((\d+)\)", payload_used, re.IGNORECASE)
                if sleep_match:
                    try:
                        injected_sleep = int(sleep_match.group(1))
                        current_timeout_seconds = max(self.http_timeout, injected_sleep + self.default_sleep_seconds + 5.0)
                    except ValueError: pass
            
            timeout = aiohttp.ClientTimeout(total=current_timeout_seconds)
            request_data_for_aiohttp = data
            if isinstance(data, dict) and method.upper() == "POST" and \
               (not current_headers.get("Content-Type") or "application/x-www-form-urlencoded" in current_headers.get("Content-Type","").lower()):
                form = aiohttp.FormData()
                for k, v_item in data.items(): form.add_field(k, str(v_item))
                request_data_for_aiohttp = form
            
            async with session.request(
                method.upper(), url, headers=current_headers, cookies=cookies, 
                data=request_data_for_aiohttp, timeout=timeout, allow_redirects=False
            ) as resp:
                aio_response_status = resp.status
                aio_response_headers = dict(resp.headers)
                response_text = await resp.text(errors='replace')
            
            duration_ms = (time.monotonic() - start_time) * 1000
            self.logger.debug(f"MySQL Response from {url}: Status {aio_response_status}, Duration: {duration_ms:.0f}ms")

            @dataclass
            class DetachedResponse: status: int; headers: Dict[str, str]; text_content: Optional[str]
            return DetachedResponse(status=aio_response_status, headers=aio_response_headers, text_content=response_text), response_text, duration_ms
        except asyncio.TimeoutError: # This is now an expected outcome for successful time-based
            self.logger.info(f"MySQL Expected Timeout ({current_timeout_seconds}s) for {method} {url} (Payload: {log_payload_snippet}) - POTENTIAL SUCCESS")
            return None, None, current_timeout_seconds * 1000 # Return the timeout duration
        except aiohttp.ClientError as e:
            self.logger.warning(f"MySQL AIOHTTP ClientError for {method} {url} (Payload: {log_payload_snippet}): {type(e).__name__} - {e}")
            return None, None, (time.monotonic() - start_time) * 1000
        except Exception as e:
            self.logger.error(f"MySQL Unexpected error for {method} {url} (Payload: {log_payload_snippet}): {e}", exc_info=True)
            return None, None, (time.monotonic() - start_time) * 1000

    def _build_request_params(self, base_url: str, injection_location: str, param_name: str, payload: str, original_value: str, method: str, original_form_data: Optional[Dict[str, str]] = None) -> Tuple[str, Optional[Dict[str, str]]]:
        target_url = base_url; request_data: Optional[Dict[str, str]] = None
        if injection_location == "url_params":
            parsed_url = urllib.parse.urlparse(base_url)
            query_params = urllib.parse.parse_qs(parsed_url.query, keep_blank_values=True)
            query_params[param_name] = [payload]
            target_url = parsed_url._replace(query=urllib.parse.urlencode(query_params, doseq=True)).geturl()
        elif injection_location in ["form_data_post", "form_data_get"] :
            request_data = (original_form_data or {}).copy()
            request_data[param_name] = payload
            target_url = base_url
            if injection_location == "form_data_get" and method.upper() == "GET":
                parsed_url = urllib.parse.urlparse(base_url)
                query_params = urllib.parse.parse_qs(parsed_url.query, keep_blank_values=True)
                for k, v_item in request_data.items(): query_params[k] = [str(v_item)]
                target_url = parsed_url._replace(query=urllib.parse.urlencode(query_params, doseq=True)).geturl()
                request_data = None
        return target_url, request_data

    async def _check_timing_dependence_async(
        self, session: aiohttp.ClientSession, base_url: str,
        original_headers: Dict[str, str], original_cookies: Dict[str, str],
        injection_details: Dict[str, Any], payload_template: str
    ) -> Tuple[bool, Optional[str], Optional[float], Optional[str]]:
        param_name = injection_details["param_name"]; original_value = injection_details["original_value"]; location = injection_details["location"]; method = injection_details.get("method", "GET"); all_form_fields = injection_details.get("all_form_fields")
        current_test_sleep_s = self.default_sleep_seconds
        sleep_values_s = [0]
        if self.blind_request_limit_for_timing > 1: sleep_values_s.append(current_test_sleep_s / 2)
        if self.blind_request_limit_for_timing > 2: sleep_values_s.append(current_test_sleep_s)
        if self.blind_request_limit_for_timing > 3: sleep_values_s.append(current_test_sleep_s * 1.5) # Max 4 points for this simple implementation
        sleep_values_s = sorted(list(set(s for s in sleep_values_s if s >=0 and s <= self.default_sleep_seconds * 2)))[:self.blind_request_limit_for_timing] # Cap sleep values
        if len(sleep_values_s) < 2 : return False, None, None, None

        observed_times_ms: List[float] = []; actual_sleeps_s: List[float] = []
        final_attack_payload_for_alert: Optional[str] = None; max_observed_time_ms: float = 0.0
        requests_this_template_timing_phase = 0

        for sleep_s in sleep_values_s:
            if self._time_requests_count_total_for_param_scan >= self.max_payload_templates_to_try * self.blind_request_limit_for_timing: break
            if requests_this_template_timing_phase >= self.blind_request_limit_for_timing: break

            payload_with_orig = payload_template.replace(ORIG_VALUE_TOKEN, original_value)
            attack_payload = payload_with_orig.replace(SLEEP_TOKEN, str(int(max(0,sleep_s)))) # Ensure sleep is not negative
            current_headers = original_headers.copy(); current_cookies = original_cookies.copy()
            if location == "header": current_headers[param_name] = attack_payload
            elif location == "cookie": current_cookies[param_name] = attack_payload
            target_url, request_data = self._build_request_params(base_url, location, param_name, attack_payload, original_value, method, all_form_fields)
            if location in ["header", "cookie"]: target_url, request_data = base_url, None
            
            self._time_requests_count_total_for_param_scan += 1
            requests_this_template_timing_phase +=1
            resp_obj, resp_text, duration_ms = await self._send_request_async(session, method, target_url, current_headers, current_cookies, request_data, param_name, attack_payload)
            
            # If timeout occurred, duration_ms will be the timeout value. This is a key indicator for time-based.
            if resp_obj is None and duration_ms >= (max(0,sleep_s) + self.default_sleep_seconds + 5 -1) * 1000 : # If it timed out close to expected
                 actual_sleeps_s.append(sleep_s); observed_times_ms.append(duration_ms)
                 if duration_ms > max_observed_time_ms: max_observed_time_ms = duration_ms; final_attack_payload_for_alert = attack_payload
                 continue # Continue to collect more data points

            if resp_obj is None: continue # Other errors, skip this data point

            if resp_text: # Check for errors even if it didn't timeout
                for err_pattern in MYSQL_ERROR_PATTERNS:
                    match = err_pattern.search(resp_text)
                    if match:
                        self.logger.info(f"MySQL Error (from Time Test): Pattern '{err_pattern.pattern}' matched for '{param_name}'")
                        return True, attack_payload, duration_ms, f"MySQL error pattern matched: {err_pattern.pattern}. Evidence: {match.group(0)[:100]}"
            
            actual_sleeps_s.append(sleep_s); observed_times_ms.append(duration_ms)
            if duration_ms > max_observed_time_ms: max_observed_time_ms = duration_ms; final_attack_payload_for_alert = attack_payload
        
        if len(actual_sleeps_s) < 2: return False, None, None, None
        if NUMPY_AVAILABLE:
            try:
                x = np.array(actual_sleeps_s); y = np.array(observed_times_ms) / 1000.0
                coeffs = np.polyfit(x, y, 1); slope = coeffs[0]
                correlation_matrix = np.corrcoef(x, y); correlation_xy = correlation_matrix[0,1]; r_squared = correlation_xy**2
                self.logger.debug(f"MySQL Timing (Numpy): Sleeps(s)={x}, Times(s)={y}, Slope={slope:.2f}, R^2={r_squared:.2f}")
                slope_ok = abs(slope - 1.0) < self.time_slope_error_range
                correlation_ok = r_squared > (1.0 - self.time_correlation_error_range)
                if slope_ok and correlation_ok:
                    evidence = f"Timing (Numpy): Sleeps(s): {actual_sleeps_s}, Times(ms): {[round(t) for t in observed_times_ms]}. Slope: {slope:.2f}, R^2: {r_squared:.2f}."
                    return True, final_attack_payload_for_alert, max_observed_time_ms, evidence
            except Exception as e_numpy: self.logger.warning(f"MySQL Timing: Numpy analysis failed: {e_numpy}.")
        
        if 0.0 in actual_sleeps_s: # Fallback simple check
            idx_zero_sleep = actual_sleeps_s.index(0.0); time_at_zero_sleep_ms = observed_times_ms[idx_zero_sleep]
            for i, s_val in enumerate(actual_sleeps_s):
                if s_val > 0:
                    t_val_ms = observed_times_ms[i]; diff_ms = t_val_ms - time_at_zero_sleep_ms
                    expected_diff_ms = s_val * 1000
                    lower_bound = expected_diff_ms * (1.0 - self.time_slope_error_range) - 500
                    upper_bound = expected_diff_ms * (1.0 + self.time_slope_error_range) + 500
                    if lower_bound <= diff_ms <= upper_bound and diff_ms > self.default_sleep_seconds * 1000 * 0.5 :
                        evidence = f"Timing (Simple): Sleeps(s): {actual_sleeps_s}, Times(ms): {[round(t) for t in observed_times_ms]}. For sleep={s_val}s, observed_delay={diff_ms:.0f}ms."
                        return True, final_attack_payload_for_alert, max_observed_time_ms, evidence
        return False, None, None, None

    async def scan(
        self,
        original_url: str,
        aiohttp_session: aiohttp.ClientSession,
        injection_details: Dict[str, Any],
        original_headers: Dict[str, str],
        original_cookies: Dict[str, str],
        # Other common args
        base_app_url: Optional[str] = None,
        html_content: Optional[str] = None,
        worker_ident: Optional[str] = "SQLiMySQLScan",
        page_specific_technologies: Optional[List[str]] = None,
        service_type_hint: Optional[str] = None,
        attack_strength: str = "MEDIUM" # Not directly used by this rule's current logic for payload selection beyond max_payload_templates_to_try
    ) -> None:
        self._time_requests_count_total_for_param_scan = 0
        
        param_name = injection_details.get("param_name")
        location = injection_details.get("location")
        target_url_for_tests = injection_details.get("action_url", original_url)

        if not param_name:
            self.logger.debug(f"[{worker_ident}] MySQL SQLi: No param_name. Skipping.")
            return

        self.logger.info(f"[{worker_ident}] Starting MySQL Time-Based SQLi for param: '{param_name}' at '{location}' on URL: {target_url_for_tests}")

        # Select a subset of payload templates to try
        payload_templates_to_use = random.sample(
            SQL_MYSQL_TIME_PAYLOAD_TEMPLATES,
            min(self.max_payload_templates_to_try, len(SQL_MYSQL_TIME_PAYLOAD_TEMPLATES))
        )
        self.logger.debug(f"[{worker_ident}] MySQL Scan: Will try {len(payload_templates_to_use)} payload templates for param '{param_name}'.")

        for payload_template in payload_templates_to_use:
            if self._time_requests_count_total_for_param_scan >= self.max_payload_templates_to_try * self.blind_request_limit_for_timing:
                self.logger.debug(f"[{worker_ident}] MySQL Scan: Reached max total time-based request limit for param '{param_name}'.")
                break
            
            is_vulnerable, attack_payload, _, evidence_details_str = await self._check_timing_dependence_async(
                aiohttp_session, target_url_for_tests, original_headers, original_cookies,
                injection_details, payload_template
            )

            if is_vulnerable and attack_payload and evidence_details_str:
                alert_name = "SQL Injection - MySQL Time Based"
                alert_desc = "A time-based SQL injection vulnerability specific to MySQL was detected."
                injection_type_str = "Time-based (MySQL SLEEP)"
                confidence = 2

                if "error pattern matched" in evidence_details_str.lower():
                    alert_name = "SQL Injection - MySQL Error Based (from Time Test)"
                    alert_desc = f"A MySQL error was detected during a time-based test: {evidence_details_str}"
                    injection_type_str = "Error-based (MySQL specific)"
                    confidence = 3

                alert = SQLiAlert(
                    cwe_id=89, name=alert_name, description=alert_desc,
                    uri=target_url_for_tests, param=param_name, attack=attack_payload,
                    evidence=evidence_details_str, rdbms=str(Tech.MySQL),
                    injection_type=injection_type_str, confidence=confidence
                )
                alert.attack_details = {"location": location, "param": param_name, "method": injection_details.get("method", "GET")}
                await self._emit_alert(alert)
                self.logger.info(f"[{worker_ident}] MySQL SQLi found for param '{param_name}'. Stopping further MySQL tests for this param.")
                break 
            
        self.logger.info(f"[{worker_ident}] MySQL SQLi scan for param: '{param_name}' completed.")